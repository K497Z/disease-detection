# import json
# import random
# import nltk
# import asyncio
# import time
# from deep_translator import GoogleTranslator
# from nltk.corpus import wordnet
#
# # å¦‚æœ NLTK ä¸‹è½½å¤±è´¥ï¼Œæ‰‹åŠ¨æŒ‡å®šæœ¬åœ°è·¯å¾„
# nltk.data.path.append("D:/nltk_data")  # ä½ å¯ä»¥ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
#
# # è¯»å– JSON æ–‡ä»¶
# input_file = r"zhiwubindu\captions\train\converted.json"
# output_file = r"zhiwubindu\captions\train\converted_augment.json"
#
# with open(input_file, "r", encoding="utf-8") as f:
#     data = json.load(f)
#
# translator = GoogleTranslator()
#
# # **å¼‚æ­¥ç¿»è¯‘**
# async def async_translate(text, src="en", dest="fr"):
#     """å¼‚æ­¥ç¿»è¯‘æ–‡æœ¬"""
#     try:
#         time.sleep(1)  # é™ä½è¯·æ±‚é¢‘ç‡ï¼Œé¿å… Google é™æµ
#         translation = await translator.translate(text, src=src, dest=dest)
#         return translation.text
#     except Exception as e:
#         print(f"å›è¯‘å¤±è´¥: {e}")
#         return text  # å¤±è´¥æ—¶è¿”å›åŸæ–‡æœ¬
#
# # **å›è¯‘**
# def back_translate(text, src="en", mid="fr"):
#     """ä½¿ç”¨ Deep Translator è¿›è¡Œå›è¯‘ï¼ˆç¨³å®šï¼‰"""
#     try:
#         time.sleep(1)  # é¿å… API é€Ÿç‡é™åˆ¶
#         french_text = GoogleTranslator(source=src, target=mid).translate(text)
#         time.sleep(1)
#         back_translated_text = GoogleTranslator(source=mid, target=src).translate(french_text)
#         return back_translated_text
#     except Exception as e:
#         print(f"å›è¯‘å¤±è´¥: {e}")
#         return text  # å¤±è´¥æ—¶è¿”å›åŸæ–‡æœ¬
#
# # **åŒä¹‰è¯æ›¿æ¢**
# def synonym_replacement(text, n=2):
#     words = text.split()
#     for _ in range(n):
#         word_candidates = [w for w in words if wordnet.synsets(w)]
#         if not word_candidates:
#             continue  # æ²¡æœ‰æ‰¾åˆ°åŒä¹‰è¯çš„å•è¯åˆ™è·³è¿‡
#         word_to_replace = random.choice(word_candidates)
#         synonyms = wordnet.synsets(word_to_replace)
#         if synonyms:
#             new_word = synonyms[0].lemmas()[0].name().replace('_', ' ')
#             words = [new_word if w == word_to_replace else w for w in words]
#     return " ".join(words)
#
# # **éšæœºæ’å…¥**
# def random_insertion(text, n=2):
#     words = text.split()
#     for _ in range(n):
#         word_candidates = [w for w in words if wordnet.synsets(w)]
#         if not word_candidates:
#             continue
#         word_to_insert = random.choice(word_candidates)
#         synonyms = wordnet.synsets(word_to_insert)
#         if synonyms:
#             new_word = synonyms[0].lemmas()[0].name().replace('_', ' ')
#             insert_pos = random.randint(0, len(words))
#             words.insert(insert_pos, new_word)
#     return " ".join(words)
#
# # **éšæœºäº¤æ¢**
# def random_swap(text, n=2):
#     words = text.split()
#     for _ in range(n):
#         if len(words) < 2:
#             continue
#         idx1, idx2 = random.sample(range(len(words)), 2)
#         words[idx1], words[idx2] = words[idx2], words[idx1]
#     return " ".join(words)
#
# # **éšæœºåˆ é™¤**
# def random_deletion(text, p=0.3):
#     words = text.split()
#     if len(words) <= 1:  # é¿å…åˆ é™¤æ‰€æœ‰å•è¯
#         return text
#     new_words = [word for word in words if random.uniform(0, 1) > p]
#     return " ".join(new_words) if new_words else text
#
# # **EDA å¢å¼º**
# def eda_augmentation(text):
#     methods = [synonym_replacement, random_insertion, random_swap, random_deletion]
#     num_augmentations = random.randint(1, 2)  # æ¯ä¸ªå¥å­è‡³å°‘ 1-2 æ¬¡å¢å¼º
#     for _ in range(num_augmentations):
#         method = random.choice(methods)
#         text = method(text)
#     return text
#
# # **å¤„ç† JSON æ•°æ®**
# for item in data:
#     new_captions = []
#     for caption in item["captions"]:
#         # print(1)
#         augmented_caption = back_translate(caption, "fr")  # å…ˆè¿›è¡Œå›è¯‘
#         augmented_caption = eda_augmentation(augmented_caption)  # ç„¶åè¿›è¡Œ EDA å¢å¼º
#         new_captions.append(augmented_caption)
#     print(item["id"])
#     item["captions_bt"] = new_captions  # å­˜å…¥å¢å¼ºåçš„æ–‡æœ¬
#
# # **ä¿å­˜å¢å¼ºåçš„ JSON**
# with open(output_file, "w", encoding="utf-8") as f:
#     json.dump(data, f, ensure_ascii=False, indent=4)
#
# print(f"å¢å¼ºå®Œæˆï¼Œæ•°æ®å·²ä¿å­˜åˆ° {output_file}")

import json
import time
import random
from deep_translator import GoogleTranslator

# è¾“å…¥ / è¾“å‡ºæ–‡ä»¶è·¯å¾„
input_file = r"zhiwubindu\captions\train\converted.json"
output_file = r"zhiwubindu\captions\train\converted_augment.json"

# è¯»å– JSON æ•°æ®
with open(input_file, "r", encoding="utf-8") as f:
    data = json.load(f)


# **å›è¯‘å‡½æ•°**
def back_translate(text, src="en", retries=3):
    """ä½¿ç”¨ Google ç¿»è¯‘è¿›è¡Œå›è¯‘ï¼Œå¹¶éšæœºé€‰æ‹©ä¸­é—´è¯­è¨€ï¼Œæ”¯æŒå¤±è´¥é‡è¯•"""
    mid_langs = ["fr", "de", "es"]  # å¯èƒ½çš„ä¸­é—´è¯­è¨€ï¼ˆæ³•è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ï¼‰

    for attempt in range(retries):
        try:
            mid = random.choice(mid_langs)  # éšæœºé€‰æ‹©ä¸€ä¸ªä¸­é—´è¯­è¨€
            time.sleep(1)  # é¿å… API é€Ÿç‡é™åˆ¶

            translated_text = GoogleTranslator(source=src, target=mid).translate(text)
            time.sleep(1)
            back_translated_text = GoogleTranslator(source=mid, target=src).translate(translated_text)

            # **æ£€æµ‹æ˜¯å¦æœ‰å˜åŒ–**
            if text == back_translated_text:
                print(f"âš ï¸ å›è¯‘æ— å˜åŒ–: {text} â†’ {back_translated_text}")
            else:
                print(f"âœ… å›è¯‘æˆåŠŸ: {text} â†’ {back_translated_text}")

            return back_translated_text  # è¿”å›å›è¯‘åçš„æ–‡æœ¬

        except Exception as e:
            print(f"âŒ ç¬¬ {attempt + 1} æ¬¡å›è¯‘å¤±è´¥: {e}")
            time.sleep(2)  # å¤±è´¥åç­‰å¾…å†å°è¯•

    print(f"â³ æœ€ç»ˆå›è¯‘å¤±è´¥ï¼Œè¿”å›åŸæ–‡æœ¬: {text}")
    return text  # å¤±è´¥å¤šæ¬¡åè¿”å›åŸæ–‡æœ¬


# **å¤„ç† JSON æ•°æ®**
for item in data:
    new_captions = []
    for caption in item["captions"]:
        augmented_caption = back_translate(caption, src="en")  # è¿›è¡Œå›è¯‘
        new_captions.append(augmented_caption)

    print(f"ğŸ“Œ å¤„ç† ID: {item['id']}")  # æ‰“å°å¤„ç†è¿›åº¦
    item["captions_bt"] = new_captions  # å­˜å…¥å›è¯‘åçš„æ–‡æœ¬

# **ä¿å­˜å¢å¼ºåçš„ JSON**
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=4)

print(f"ğŸ‰ å›è¯‘å®Œæˆï¼Œæ•°æ®å·²ä¿å­˜åˆ° {output_file}")
